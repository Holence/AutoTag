{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(mean, std, amount=100):\n",
    "    if len(mean)!=len(std):\n",
    "        raise(\"Different Dim!\")\n",
    "    dim=len(mean)\n",
    "    data=torch.empty((amount, dim), device=device)\n",
    "    for i in range(dim):\n",
    "        data[:,i]=data[:,i].normal_(mean=mean[i], std=std[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM=3\n",
    "CLASS_NUM=20\n",
    "SAMPLE_NUM=10\n",
    "SAMPLE_NUM_RANGE=0.5\n",
    "MEAN_ARRANGE=100\n",
    "STD_ARRANGE=10\n",
    "SAMPLE_SHIFTING=True\n",
    "\n",
    "if INPUT_DIM==2:\n",
    "    # 2D\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in range(CLASS_NUM):\n",
    "        mean_list.append([random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE])\n",
    "        std_list.append([0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE])\n",
    "    \n",
    "    data={}\n",
    "    for i in range(len(mean_list)):\n",
    "        temp=normal_distribution(mean_list[i], std_list[i], int( (1 + random.sample([1, -1], 1)[0] * random.random() * SAMPLE_NUM_RANGE) * SAMPLE_NUM))\n",
    "        data[str(i)]=temp\n",
    "\n",
    "    if CLASS_NUM<=25:\n",
    "        for tag in data:\n",
    "            plt.scatter(data[tag][:, 0].cpu(), data[tag][:, 1].cpu())\n",
    "elif INPUT_DIM==3:\n",
    "    # 3D\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in range(CLASS_NUM):\n",
    "        mean_list.append([random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE])\n",
    "        std_list.append([0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE])\n",
    "\n",
    "    data={}\n",
    "    for i in range(len(mean_list)):\n",
    "        temp=normal_distribution(mean_list[i], std_list[i], int( (1 + random.sample([1, -1], 1)[0] * random.random() * SAMPLE_NUM_RANGE) * SAMPLE_NUM))\n",
    "        data[str(i)]=temp\n",
    "\n",
    "    if CLASS_NUM<=25:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in data:\n",
    "            ax.scatter(data[tag][:, 0].cpu(), data[tag][:, 1].cpu(), data[tag][:, 2].cpu())\n",
    "else:\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in range(CLASS_NUM):\n",
    "        mean_list.append([random.random()*MEAN_ARRANGE for i in range(INPUT_DIM)])\n",
    "        std_list.append([0.5+random.random()*STD_ARRANGE for i in range(INPUT_DIM)])\n",
    "    \n",
    "    data={}\n",
    "    for i in range(len(mean_list)):\n",
    "        temp=normal_distribution(mean_list[i], std_list[i], int( (1 + random.sample([1, -1], 1)[0] * random.random() * SAMPLE_NUM_RANGE) * SAMPLE_NUM))\n",
    "        data[str(i)]=temp\n",
    "\n",
    "train_pipe=[]\n",
    "train_dict={}\n",
    "test_dict={}\n",
    "for tag in data:\n",
    "    train, test = train_test_split([i for i in data[tag]], test_size=0.2)\n",
    "    # 为了测试持续学习的性能，类别内的样本分布应该在变化（漂移）\n",
    "    # 这里每一类内的样本按照到原点的距离排序\n",
    "    if SAMPLE_SHIFTING:\n",
    "        train = sorted(train, key = lambda x: torch.linalg.norm(x))\n",
    "    train_pipe.extend([(_,tag) for _ in train])\n",
    "    train_dict[tag]=train\n",
    "    test_dict[tag]=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(Model, batch_size, shuffle=False, evaluate=True):\n",
    "    if shuffle:\n",
    "        pipe = random.sample(train_pipe, len(train_pipe))\n",
    "    else:\n",
    "        pipe = train_pipe.copy()\n",
    "    \n",
    "    for i in range(0, len(pipe)+batch_size, batch_size):\n",
    "        if pipe[i:i+batch_size] and Model.iteration<len(train_pipe):\n",
    "            Model.batch_train(pipe[i:i+batch_size])\n",
    "            if evaluate:\n",
    "                if Model.iteration%int(SAMPLE_NUM*(1-SAMPLE_NUM_RANGE))==0:\n",
    "                    predict_trainset(Model, silent=True)\n",
    "                    predict_testset(Model, silent=True)\n",
    "\n",
    "def continual_forward_baseline(Model, shuffle=False, evaluate=True):\n",
    "    if shuffle:\n",
    "        pipe = random.sample(train_pipe, len(train_pipe))\n",
    "    else:\n",
    "        pipe = train_pipe.copy()\n",
    "    for i in tqdm(pipe):\n",
    "        Model.continual_forward_baseline(i[0],i[1])\n",
    "        if evaluate:\n",
    "            if Model.iteration%int(SAMPLE_NUM*(1-SAMPLE_NUM_RANGE))==0:\n",
    "                predict_trainset(Model, silent=True)\n",
    "                predict_testset(Model, silent=True)\n",
    "\n",
    "def continual_train(Model, shuffle=False, evaluate=True):\n",
    "    if shuffle:\n",
    "        pipe = random.sample(train_pipe, len(train_pipe))\n",
    "    else:\n",
    "        pipe = train_pipe.copy()\n",
    "    for i in tqdm(pipe):\n",
    "        Model.continual_forward(i[0],i[1])\n",
    "        if evaluate:\n",
    "            if Model.iteration%int(SAMPLE_NUM*(1-SAMPLE_NUM_RANGE))==0:\n",
    "                predict_trainset(Model, silent=True)\n",
    "                predict_testset(Model, silent=True)\n",
    "\n",
    "def predict_trainset(Model, silent=False):\n",
    "    acc_list=[]\n",
    "    total=0\n",
    "    total_correct=0\n",
    "    forgetting_list=[]\n",
    "    for key, value in train_dict.items():\n",
    "        total+=len(value)\n",
    "        if Model.tag_dict.get(key):\n",
    "            correct=0\n",
    "            pred_tags_list=Model.predict(value)\n",
    "            for pred_tags in pred_tags_list:\n",
    "                if key in pred_tags:\n",
    "                    correct+=1\n",
    "            total_correct+=correct\n",
    "            acc=correct/len(value)\n",
    "            metric_dict[\"Train\"][key].append([Model.iteration, acc])\n",
    "            acc_list.append(acc)\n",
    "            if len(metric_dict[\"Train\"][key])>1:\n",
    "                forgetting_list.append(metric_dict[\"Train\"][key][0][1] - metric_dict[\"Train\"][key][-1][1])\n",
    "        else:\n",
    "            acc_list.append(0)\n",
    "    \n",
    "    total_acc=total_correct/total\n",
    "    metric_dict[\"Train\"][\"Total ACC\"].append([Model.iteration, total_acc])\n",
    "    \n",
    "    average_acc=sum(acc_list)/len(acc_list)\n",
    "    metric_dict[\"Train\"][\"Average ACC\"].append([Model.iteration, average_acc])\n",
    "\n",
    "    if forgetting_list:\n",
    "        forgetting_rate=sum(forgetting_list)/len(forgetting_list)\n",
    "        metric_dict[\"Train\"][\"Forgetting Rate\"].append([Model.iteration, forgetting_rate])\n",
    "        \n",
    "    if not silent:\n",
    "        print(\"Total Acc\", total_acc)\n",
    "        print(\"Average Acc\", average_acc)\n",
    "\n",
    "def predict_testset(Model, silent=False):\n",
    "    acc_list=[]\n",
    "    total=0\n",
    "    total_correct=0\n",
    "    forgetting_list=[]\n",
    "    for key, value in test_dict.items():\n",
    "        total+=len(value)\n",
    "        if Model.tag_dict.get(key):\n",
    "            correct=0\n",
    "            pred_tags_list=Model.predict(value)\n",
    "            for pred_tags in pred_tags_list:\n",
    "                if key in pred_tags:\n",
    "                    correct+=1\n",
    "            total_correct+=correct\n",
    "            acc=correct/len(value)\n",
    "            metric_dict[\"Test\"][key].append([Model.iteration, acc])\n",
    "            acc_list.append(acc)\n",
    "            if len(metric_dict[\"Test\"][key])>1:\n",
    "                forgetting_list.append(metric_dict[\"Test\"][key][0][1] - metric_dict[\"Test\"][key][-1][1])\n",
    "        else:\n",
    "            acc_list.append(0)\n",
    "    \n",
    "    total_acc=total_correct/total\n",
    "    metric_dict[\"Test\"][\"Total ACC\"].append([Model.iteration, total_acc])\n",
    "    \n",
    "    average_acc=sum(acc_list)/len(acc_list)\n",
    "    metric_dict[\"Test\"][\"Average ACC\"].append([Model.iteration, average_acc])\n",
    "\n",
    "    if forgetting_list:\n",
    "        forgetting_rate=sum(forgetting_list)/len(forgetting_list)\n",
    "        metric_dict[\"Test\"][\"Forgetting Rate\"].append([Model.iteration, forgetting_rate])\n",
    "\n",
    "    if not silent:\n",
    "        print(\"Total Acc\", total_acc)\n",
    "        print(\"Average Acc\", average_acc)\n",
    "\n",
    "def predict_train_and_paint(Model):\n",
    "    predict_result={}\n",
    "    for key, value in tqdm(train_dict.items()):\n",
    "        pred_tags_list=Model.predict(value)\n",
    "        for pred_tags, sample in zip(pred_tags_list, value):\n",
    "            pred_tag=pred_tags[0]\n",
    "            if not predict_result.get(pred_tag):\n",
    "                predict_result[pred_tag]=[sample]\n",
    "            else:\n",
    "                predict_result[pred_tag].append(sample)\n",
    "    predict_result=dict(sorted(predict_result.items(), key=lambda x:x[0]))\n",
    "    if INPUT_DIM==2:\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            plt.scatter(t[:, 0], t[:, 1], label=tag)\n",
    "        # plt.legend()\n",
    "        plt.title(\"Train\")\n",
    "    elif INPUT_DIM==3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            ax.scatter(t[:, 0].cpu(), t[:, 1].cpu(), t[:, 2].cpu(), label=tag)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        # ax.legend()\n",
    "        plt.title(\"Train\")\n",
    "\n",
    "def predict_test_and_paint(Model):\n",
    "    predict_result={}\n",
    "    for key, value in tqdm(test_dict.items()):\n",
    "        pred_tags_list=Model.predict(value)\n",
    "        for pred_tags, sample in zip(pred_tags_list, value):\n",
    "            pred_tag=pred_tags[0]\n",
    "            if not predict_result.get(pred_tag):\n",
    "                predict_result[pred_tag]=[sample]\n",
    "            else:\n",
    "                predict_result[pred_tag].append(sample)\n",
    "    predict_result=dict(sorted(predict_result.items(), key=lambda x:x[0]))\n",
    "    if INPUT_DIM==2:\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            plt.scatter(t[:, 0], t[:, 1], label=tag)\n",
    "        # plt.legend()\n",
    "        plt.title(\"Test\")\n",
    "    elif INPUT_DIM==3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            ax.scatter(t[:, 0].cpu(), t[:, 1].cpu(), t[:, 2].cpu(), label=tag)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        # ax.legend()\n",
    "        plt.title(\"Test\")\n",
    "\n",
    "def plot_loss(Model):\n",
    "    plt.figure()\n",
    "    keys=[]\n",
    "    for key in Model.loss_dict.keys():\n",
    "        if Model.loss_dict[key]:\n",
    "            t=torch.tensor(Model.loss_dict[key])\n",
    "            plt.plot(t[:,0], t[:,1])\n",
    "            keys.append(key)\n",
    "    plt.legend(keys)\n",
    "    plt.show()\n",
    "\n",
    "def plot_acc():\n",
    "    if CLASS_NUM<=25:\n",
    "        plt.figure(figsize=(16,8))\n",
    "        ax=plt.subplot(1,2,1)\n",
    "        for key in [i for i in metric_dict[\"Train\"].keys() if i not in [\"Average ACC\", \"Total ACC\", \"Forgetting Rate\"]]:\n",
    "            t=torch.tensor(metric_dict[\"Train\"][key])\n",
    "            ax.plot(t[:,0], t[:,1], label=key)\n",
    "        ax.set_ylim(top=1.1, bottom=-0.1)\n",
    "        ax.set_title(\"Train ACC\")\n",
    "        ax.legend()\n",
    "\n",
    "        ax=plt.subplot(1,2,2)\n",
    "        for key in [i for i in metric_dict[\"Test\"].keys() if i not in [\"Average ACC\", \"Total ACC\", \"Forgetting Rate\"]]:\n",
    "            t=torch.tensor(metric_dict[\"Test\"][key])\n",
    "            ax.plot(t[:,0], t[:,1], label=key)\n",
    "        ax.set_ylim(top=1.1, bottom=-0.1)\n",
    "        ax.set_title(\"Test ACC\")\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "def initialize():\n",
    "    global metric_dict\n",
    "    metric_dict={\n",
    "        \"Train\":{},\n",
    "        \"Test\":{},\n",
    "    }\n",
    "    \n",
    "    for tag in train_dict:\n",
    "        if metric_dict[\"Train\"].get(tag)==None:\n",
    "            metric_dict[\"Train\"][tag]=[]\n",
    "            metric_dict[\"Train\"][tag]=[]\n",
    "    metric_dict[\"Train\"][\"Total ACC\"]=[]\n",
    "    metric_dict[\"Train\"][\"Average ACC\"]=[]\n",
    "    metric_dict[\"Train\"][\"Forgetting Rate\"]=[]\n",
    "    \n",
    "    for tag in train_dict:\n",
    "        if metric_dict[\"Test\"].get(tag)==None:\n",
    "            metric_dict[\"Test\"][tag]=[]\n",
    "            metric_dict[\"Test\"][tag]=[]\n",
    "    metric_dict[\"Test\"][\"Total ACC\"]=[]\n",
    "    metric_dict[\"Test\"][\"Average ACC\"]=[]\n",
    "    metric_dict[\"Test\"][\"Forgetting Rate\"]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_DIM=9\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = torch.nn.Linear(INPUT_DIM, INNER_DIM)\n",
    "        init_network(self)\n",
    "\n",
    "    def forward(self, feature_vecs):\n",
    "        out = self.fc(feature_vecs)\n",
    "        return out\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = torch.nn.Linear(INNER_DIM, INPUT_DIM)\n",
    "        init_network(self)\n",
    "\n",
    "    def forward(self, tag_vecs):\n",
    "        out = self.fc(tag_vecs)\n",
    "        return out\n",
    "\n",
    "class EmptyModel(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t=t.reshape(1,-1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE=False\n",
    "CLS_LR=0.001\n",
    "GEN_LR=0.01\n",
    "TRAIN_ALONG=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserve_metric(suffix):\n",
    "    for key in [i for i in metric_dict[\"Train\"].keys() if i in [\"Average ACC\", \"Total ACC\", \"Forgetting Rate\"]]:\n",
    "        metric_reservation[\"Train\"][key+\" \"+suffix]=metric_dict[\"Train\"][key].copy()\n",
    "    for key in [i for i in metric_dict[\"Test\"].keys() if i in [\"Average ACC\", \"Total ACC\", \"Forgetting Rate\"]]:\n",
    "        metric_reservation[\"Test\"][key+\" \"+suffix]=metric_dict[\"Test\"][key].copy()\n",
    "\n",
    "metric_reservation_list=[]\n",
    "for i in range(5):\n",
    "    SEED=random.randint(1, 999999)\n",
    "\n",
    "    metric_reservation={\n",
    "        \"Train\":{},\n",
    "        \"Test\":{},\n",
    "    }\n",
    "    \n",
    "    from ContinualLearning import BaseModel\n",
    "    set_seed(SEED)\n",
    "    Model=BaseModel(EmptyModel, Classifier, CLS_LR)\n",
    "    batch_size=SAMPLE_NUM*2\n",
    "    initialize()\n",
    "    for i in tqdm(range(batch_size)):\n",
    "        batch_train(Model, batch_size, shuffle=True)\n",
    "    predict_trainset(Model, silent=True)\n",
    "    predict_testset(Model, silent=True)\n",
    "    reserve_metric(\"Batch\")\n",
    "\n",
    "    from ContinualLearning import BaseModel\n",
    "    set_seed(SEED)\n",
    "    Model=BaseModel(EmptyModel, Classifier, CLS_LR)\n",
    "    initialize()\n",
    "    continual_forward_baseline(Model, shuffle=SHUFFLE)\n",
    "    predict_trainset(Model, silent=True)\n",
    "    predict_testset(Model, silent=True)\n",
    "    reserve_metric(\"Baseline\")\n",
    "\n",
    "    from ContinualLearning import ContinualLearningModel_Store\n",
    "    set_seed(SEED)\n",
    "    Model=ContinualLearningModel_Store(EmptyModel, Classifier, CLS_LR, TRAIN_ALONG)\n",
    "    initialize()\n",
    "    continual_train(Model, shuffle=SHUFFLE)\n",
    "    predict_trainset(Model, silent=True)\n",
    "    predict_testset(Model, silent=True)\n",
    "    reserve_metric(\"Store\")\n",
    "\n",
    "    from ContinualLearning import ContinualLearningModel_Generate\n",
    "    set_seed(SEED)\n",
    "    Model=ContinualLearningModel_Generate(EmptyModel, Classifier, CLS_LR, TRAIN_ALONG, Generator, GEN_LR)\n",
    "    initialize()\n",
    "    continual_train(Model, shuffle=SHUFFLE)\n",
    "    predict_trainset(Model, silent=True)\n",
    "    predict_testset(Model, silent=True)\n",
    "    reserve_metric(\"Generate\")\n",
    "\n",
    "    metric_reservation_list.append(metric_reservation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16,16))\n",
    "\n",
    "o=1\n",
    "# verticals=[\"Average ACC\", \"Total ACC\", \"Forgetting Rate\"]\n",
    "verticals=[\"Average ACC\", \"Forgetting Rate\"]\n",
    "horizontals=[\"Train\", \"Test\"]\n",
    "for criterion in verticals:\n",
    "    for mode in horizontals:\n",
    "        ax=plt.subplot(len(verticals), len(horizontals), o)\n",
    "        top=0\n",
    "        bottom=1\n",
    "        tt={}\n",
    "        for metric_reservation in metric_reservation_list:\n",
    "            colors=[\"#00A2FF20\", \"#00000020\", \"#FF000020\", \"#00FF0020\"]\n",
    "            for key in [j for j in metric_reservation[mode].keys() if criterion in j]:\n",
    "                t=torch.tensor(metric_reservation[mode][key])\n",
    "                if not tt.get(key):\n",
    "                    tt[key]=[t]\n",
    "                else:\n",
    "                    tt[key].append(t)\n",
    "                ax.plot(t[:,0], t[:,1], color=colors[0])\n",
    "                colors.pop(0)\n",
    "        \n",
    "        colors=[\"#00A2FF\", \"#000000\", \"#FF0000\", \"#00FF00\"]\n",
    "        for key in [j for j in metric_reservation[mode].keys() if criterion in j]:\n",
    "            t=torch.stack(tt[key]).mean(dim=0)\n",
    "            bottom=min(torch.min(t[:, 1]).tolist(), bottom)\n",
    "            top=max(torch.max(t[:, 1]).tolist(), top)\n",
    "            ax.plot(t[:,0], t[:,1], label=key, color=colors[0])\n",
    "            colors.pop(0)\n",
    "        \n",
    "        ax.set_xlabel(\"iteration\", loc=\"right\")\n",
    "        ax.set_ylim(top=top+0.1, bottom=bottom-0.1)\n",
    "        ax.set_title(f\"{mode} {criterion}\")\n",
    "        ax.legend()\n",
    "        o+=1\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
