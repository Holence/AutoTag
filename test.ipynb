{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "set_seed(123)\n",
    "\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(mean, std, amount=100):\n",
    "    if len(mean)!=len(std):\n",
    "        raise(\"Different Dim!\")\n",
    "    dim=len(mean)\n",
    "    data=torch.empty((amount, dim), device=device)\n",
    "    for i in range(dim):\n",
    "        data[:,i]=data[:,i].normal_(mean=mean[i], std=std[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM=3\n",
    "CLASS_NUM=20\n",
    "SAMPLE_NUM=10\n",
    "MEAN_ARRANGE=50\n",
    "STD_ARRANGE=6\n",
    "\n",
    "if INPUT_DIM==2:\n",
    "    # 2D\n",
    "    # mean_list=[\n",
    "    #     [1,1],\n",
    "    #     [10,10],\n",
    "    #     [3,5],\n",
    "    #     [10,4],\n",
    "    # ]\n",
    "    # std_list=[\n",
    "    #     [1,0.2],\n",
    "    #     [0.5,0.5],\n",
    "    #     [.5,.2],\n",
    "    #     [.8,1],\n",
    "    # ]\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in range(CLASS_NUM):\n",
    "        mean_list.append([random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE])\n",
    "        std_list.append([0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE])\n",
    "    \n",
    "    data={}\n",
    "    for i in range(len(mean_list)):\n",
    "        temp=normal_distribution(mean_list[i], std_list[i], SAMPLE_NUM)\n",
    "        data[str(i)]=temp\n",
    "\n",
    "    if CLASS_NUM<=25:\n",
    "        for tag in data:\n",
    "            plt.scatter(data[tag][:, 0].cpu(), data[tag][:, 1].cpu(), label=tag)\n",
    "        plt.legend()\n",
    "elif INPUT_DIM==3:\n",
    "    # 3D\n",
    "    # mean_list=[\n",
    "    #     [1,1,1],\n",
    "    #     [10,10,10],\n",
    "    #     [3,5,8],\n",
    "    #     [8,5,0],\n",
    "    # ]\n",
    "    # std_list=[\n",
    "    #     [1,0.2,1],\n",
    "    #     [0.5,0.5,0.5],\n",
    "    #     [1,2,2],\n",
    "    #     [.8,2,.5],\n",
    "    # ]\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in range(CLASS_NUM):\n",
    "        mean_list.append([random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE])\n",
    "        std_list.append([0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE])\n",
    "\n",
    "    data={}\n",
    "    for i in range(len(mean_list)):\n",
    "        temp=normal_distribution(mean_list[i], std_list[i], SAMPLE_NUM)\n",
    "        data[str(i)]=temp\n",
    "\n",
    "    if CLASS_NUM<=25:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in data:\n",
    "            ax.scatter(data[tag][:, 0].cpu(), data[tag][:, 1].cpu(), data[tag][:, 2].cpu(), label=tag)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.legend()\n",
    "\n",
    "train_pipe=[]\n",
    "train_dict={}\n",
    "test_dict={}\n",
    "for tag in data:\n",
    "    train, test = train_test_split([i for i in data[tag]], test_size=0.2)\n",
    "    train_pipe.extend([(_,tag) for _ in train])\n",
    "    train_dict[tag]=train\n",
    "    test_dict[tag]=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(batch_size):\n",
    "    shuffled = random.sample(train_pipe, len(train_pipe))\n",
    "    for i in range(0, len(shuffled)+batch_size, batch_size):\n",
    "        if train_pipe[i:i+batch_size]:\n",
    "            loss=Model.batch_train(train_pipe[i:i+batch_size])\n",
    "    Model.epoch+=1\n",
    "    Model.loss_dict[\"Classifier Batch Train Loss\"].append((Model.epoch, loss))\n",
    "\n",
    "def continual_forward_baseline(shuffle=False):\n",
    "    if shuffle:\n",
    "        pipe = random.sample(train_pipe, len(train_pipe))\n",
    "    else:\n",
    "        pipe = train_pipe.copy()\n",
    "    \n",
    "    for i in tqdm(pipe):\n",
    "        Model.continual_forward_baseline(i[0],i[1])\n",
    "        if Model.epoch%SAMPLE_NUM==int(SAMPLE_NUM/2):\n",
    "            predict_trainset(silent=True)\n",
    "            predict_testset(silent=True)\n",
    "\n",
    "def continual_train(shuffle=False):\n",
    "    if shuffle:\n",
    "        pipe = random.sample(train_pipe, len(train_pipe))\n",
    "    else:\n",
    "        pipe = train_pipe.copy()\n",
    "    \n",
    "    for i in tqdm(pipe):\n",
    "        Model.continual_forward(i[0],i[1])\n",
    "        if Model.epoch%SAMPLE_NUM==int(SAMPLE_NUM/2):\n",
    "            predict_trainset(silent=True)\n",
    "            predict_testset(silent=True)\n",
    "\n",
    "def predict_trainset(silent=False):\n",
    "    total=0\n",
    "    total_correct=0\n",
    "    # for key, value in tqdm(train_dict.items()):\n",
    "    for key, value in train_dict.items():\n",
    "        if Model.tag_dict.get(key):\n",
    "            total+=len(value)\n",
    "            current_correct=0\n",
    "            pred_tags_list=Model.predict(value)\n",
    "            for pred_tags in pred_tags_list:\n",
    "                if key in pred_tags:\n",
    "                    total_correct+=1\n",
    "                    current_correct+=1\n",
    "            acc=current_correct/len(value)\n",
    "            acc_dict[key+\"_train\"].append([Model.epoch, acc])\n",
    "    total_acc=total_correct/total\n",
    "    acc_dict[\"total_train\"].append([Model.epoch, total_acc])\n",
    "    if not silent:\n",
    "        print(total_acc)\n",
    "\n",
    "def predict_testset(silent=False):\n",
    "    total=0\n",
    "    total_correct=0\n",
    "    # for key, value in tqdm(train_dict.items()):\n",
    "    for key, value in test_dict.items():\n",
    "        if Model.tag_dict.get(key):\n",
    "            total+=len(value)\n",
    "            current_correct=0\n",
    "            pred_tags_list=Model.predict(value)\n",
    "            for pred_tags in pred_tags_list:\n",
    "                if key in pred_tags:\n",
    "                    total_correct+=1\n",
    "                    current_correct+=1\n",
    "            acc=current_correct/len(value)\n",
    "            acc_dict[key+\"_test\"].append([Model.epoch, acc])\n",
    "    total_acc=total_correct/total\n",
    "    acc_dict[\"total_test\"].append([Model.epoch, total_acc])\n",
    "    if not silent:\n",
    "        print(total_acc)\n",
    "\n",
    "def predict_train_and_paint():\n",
    "    predict_result={}\n",
    "    for key, value in tqdm(train_dict.items()):\n",
    "        pred_tags_list=Model.predict(value)\n",
    "        for pred_tags, sample in zip(pred_tags_list, value):\n",
    "            pred_tag=pred_tags[0]\n",
    "            if not predict_result.get(pred_tag):\n",
    "                predict_result[pred_tag]=[sample]\n",
    "            else:\n",
    "                predict_result[pred_tag].append(sample)\n",
    "    predict_result=dict(sorted(predict_result.items(), key=lambda x:x[0]))\n",
    "    if INPUT_DIM==2:\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            plt.scatter(t[:, 0], t[:, 1], label=tag)\n",
    "        # plt.legend()\n",
    "        plt.title(\"TRAIN\")\n",
    "    elif INPUT_DIM==3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            ax.scatter(t[:, 0].cpu(), t[:, 1].cpu(), t[:, 2].cpu(), label=tag)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        # ax.legend()\n",
    "        plt.title(\"TRAIN\")\n",
    "\n",
    "def predict_test_and_paint():\n",
    "    predict_result={}\n",
    "    for key, value in tqdm(test_dict.items()):\n",
    "        pred_tags_list=Model.predict(value)\n",
    "        for pred_tags, sample in zip(pred_tags_list, value):\n",
    "            pred_tag=pred_tags[0]\n",
    "            if not predict_result.get(pred_tag):\n",
    "                predict_result[pred_tag]=[sample]\n",
    "            else:\n",
    "                predict_result[pred_tag].append(sample)\n",
    "    predict_result=dict(sorted(predict_result.items(), key=lambda x:x[0]))\n",
    "    if INPUT_DIM==2:\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            plt.scatter(t[:, 0], t[:, 1], label=tag)\n",
    "        # plt.legend()\n",
    "        plt.title(\"TEST\")\n",
    "    elif INPUT_DIM==3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            ax.scatter(t[:, 0].cpu(), t[:, 1].cpu(), t[:, 2].cpu(), label=tag)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        # ax.legend()\n",
    "        plt.title(\"TEST\")\n",
    "\n",
    "def plot_loss():\n",
    "    plt.figure()\n",
    "    keys=[]\n",
    "    for key in Model.loss_dict.keys():\n",
    "        if Model.loss_dict[key]:\n",
    "            t=torch.tensor(Model.loss_dict[key])\n",
    "            plt.plot(t[:,0], t[:,1])\n",
    "            keys.append(key)\n",
    "    plt.legend(keys)\n",
    "    plt.show()\n",
    "\n",
    "def plot_acc():\n",
    "    plt.figure(figsize=(16,8))\n",
    "    ax=plt.subplot(1,2,1)\n",
    "    for key in [i for i in acc_dict.keys() if \"total\" not in i and \"train\" in i]:\n",
    "        t=torch.tensor(acc_dict[key])\n",
    "        ax.plot(t[:,0], t[:,1], label=key[:-6])\n",
    "    ax.set_ylim(top=1.1, bottom=-0.1)\n",
    "    ax.set_title(\"Train ACC\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax=plt.subplot(1,2,2)\n",
    "    for key in [i for i in acc_dict.keys() if \"total\" not in i and \"test\" in i]:\n",
    "        t=torch.tensor(acc_dict[key])\n",
    "        ax.plot(t[:,0], t[:,1], label=key[:-5])\n",
    "    ax.set_ylim(top=1.1, bottom=-0.1)\n",
    "    ax.set_title(\"Test ACC\")\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def initialize():\n",
    "    global acc_dict\n",
    "    acc_dict={}\n",
    "    for tag in train_dict:\n",
    "        if acc_dict.get(tag)==None:\n",
    "            acc_dict[tag+\"_test\"]=[]\n",
    "            acc_dict[tag+\"_train\"]=[]\n",
    "    acc_dict[\"total_train\"]=[]\n",
    "    acc_dict[\"total_test\"]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_DIM=100\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = torch.nn.Linear(INPUT_DIM, INNER_DIM)\n",
    "        init_network(self)\n",
    "\n",
    "    def forward(self, feature_vecs):\n",
    "        out = self.fc(feature_vecs)\n",
    "        return out\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = torch.nn.Linear(INNER_DIM, INPUT_DIM)\n",
    "        init_network(self)\n",
    "\n",
    "    def forward(self, tag_vecs):\n",
    "        out = self.fc(tag_vecs)\n",
    "        return out\n",
    "\n",
    "class EmptyModel(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t=t.reshape(1,-1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_reservation={}\n",
    "SEED=random.randint(1, 999999)\n",
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ContinualLearning import BaseModel\n",
    "set_seed(SEED)\n",
    "Model=BaseModel(\n",
    "    EmptyModel,\n",
    "    Classifier,\n",
    "    0.001\n",
    ")\n",
    "\n",
    "initialize()\n",
    "for i in tqdm(range(100)):\n",
    "    batch_train(16)\n",
    "plot_loss()\n",
    "\n",
    "acc_reservation[\"total_train_batch\"]=acc_dict[\"total_train\"].copy()\n",
    "acc_reservation[\"total_test_batch\"]=acc_dict[\"total_test\"].copy()\n",
    "\n",
    "predict_trainset()\n",
    "predict_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ContinualLearning import BaseModel\n",
    "set_seed(SEED)\n",
    "Model=BaseModel(\n",
    "    EmptyModel,\n",
    "    Classifier,\n",
    "    0.001\n",
    ")\n",
    "\n",
    "initialize()\n",
    "continual_forward_baseline()\n",
    "plot_loss()\n",
    "plot_acc()\n",
    "\n",
    "acc_reservation[\"total_train_baseline\"]=acc_dict[\"total_train\"].copy()\n",
    "acc_reservation[\"total_test_baseline\"]=acc_dict[\"total_test\"].copy()\n",
    "\n",
    "predict_trainset()\n",
    "predict_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ContinualLearning import ContinualLearningModel_Store\n",
    "set_seed(SEED)\n",
    "Model=ContinualLearningModel_Store(\n",
    "    EmptyModel,\n",
    "    Classifier,\n",
    "    0.001, 99\n",
    ")\n",
    "\n",
    "initialize()\n",
    "continual_train()\n",
    "plot_loss()\n",
    "plot_acc()\n",
    "\n",
    "acc_reservation[\"total_train_\"]=acc_dict[\"total_train\"].copy()\n",
    "acc_reservation[\"total_test_\"]=acc_dict[\"total_test\"].copy()\n",
    "\n",
    "predict_trainset()\n",
    "predict_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_reservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train_and_paint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_and_paint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
