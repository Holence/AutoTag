{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "from ContinualLearning import ContinualLearningModel\n",
    "set_seed(123)\n",
    "\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(mean, std, amount=100):\n",
    "    if len(mean)!=len(std):\n",
    "        raise(\"Different Dim!\")\n",
    "    dim=len(mean)\n",
    "    data=torch.empty((amount, dim), device=device)\n",
    "    for i in range(dim):\n",
    "        data[:,i]=data[:,i].normal_(mean=mean[i], std=std[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM=3\n",
    "CLASS_NUM=20\n",
    "SAMPLE_NUM=10\n",
    "MEAN_ARRANGE=100\n",
    "STD_ARRANGE=4\n",
    "\n",
    "if INPUT_DIM==2:\n",
    "    # 2D\n",
    "    # mean_list=[\n",
    "    #     [1,1],\n",
    "    #     [10,10],\n",
    "    #     [3,5],\n",
    "    #     [10,4],\n",
    "    # ]\n",
    "    # std_list=[\n",
    "    #     [1,0.2],\n",
    "    #     [0.5,0.5],\n",
    "    #     [.5,.2],\n",
    "    #     [.8,1],\n",
    "    # ]\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in range(CLASS_NUM):\n",
    "        mean_list.append([random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE])\n",
    "        std_list.append([0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE])\n",
    "    \n",
    "    data={}\n",
    "    for i in range(len(mean_list)):\n",
    "        temp=normal_distribution(mean_list[i], std_list[i], SAMPLE_NUM)\n",
    "        data[str(i)]=temp\n",
    "\n",
    "    if CLASS_NUM<=25:\n",
    "        for tag in data:\n",
    "            plt.scatter(data[tag][:, 0].cpu(), data[tag][:, 1].cpu(), label=tag)\n",
    "        plt.legend()\n",
    "elif INPUT_DIM==3:\n",
    "    # 3D\n",
    "    # mean_list=[\n",
    "    #     [1,1,1],\n",
    "    #     [10,10,10],\n",
    "    #     [3,5,8],\n",
    "    #     [8,5,0],\n",
    "    # ]\n",
    "    # std_list=[\n",
    "    #     [1,0.2,1],\n",
    "    #     [0.5,0.5,0.5],\n",
    "    #     [1,2,2],\n",
    "    #     [.8,2,.5],\n",
    "    # ]\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in range(CLASS_NUM):\n",
    "        mean_list.append([random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE, random.random()*MEAN_ARRANGE])\n",
    "        std_list.append([0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE, 0.5+random.random()*STD_ARRANGE])\n",
    "\n",
    "    data={}\n",
    "    for i in range(len(mean_list)):\n",
    "        temp=normal_distribution(mean_list[i], std_list[i], SAMPLE_NUM)\n",
    "        data[str(i)]=temp\n",
    "\n",
    "    if CLASS_NUM<=25:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in data:\n",
    "            ax.scatter(data[tag][:, 0].cpu(), data[tag][:, 1].cpu(), data[tag][:, 2].cpu(), label=tag)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.legend()\n",
    "\n",
    "train_pipe=[]\n",
    "train_dict={}\n",
    "test_dict={}\n",
    "for tag in data:\n",
    "    train, test = train_test_split([i for i in data[tag]], test_size=0.2)\n",
    "    train_pipe.extend([(_,tag) for _ in train])\n",
    "    train_dict[tag]=train\n",
    "    test_dict[tag]=test\n",
    "\n",
    "# random.shuffle(train_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continual_train():\n",
    "    # random.shuffle(train_pipe)\n",
    "    global epoch\n",
    "    for i in tqdm(train_pipe):\n",
    "        epoch+=1\n",
    "        Model.continual_forward(i[0],i[1])\n",
    "        predict_trainset(epoch)\n",
    "        predict_testset(epoch)\n",
    "\n",
    "def continual_train_without_generator():\n",
    "    # random.shuffle(train_pipe)\n",
    "    global epoch\n",
    "    for i in tqdm(train_pipe):\n",
    "        epoch+=1\n",
    "        Model.continual_forward_without_generator(i[0],i[1])\n",
    "        predict_trainset(epoch)\n",
    "        predict_testset(epoch)\n",
    "\n",
    "def batch_train(batch_size):\n",
    "    shuffled = random.sample(train_pipe, len(train_pipe))\n",
    "    Model.batch_train(shuffled, batch_size)\n",
    "\n",
    "def predict_trainset(epoch=None):\n",
    "    total=0\n",
    "    total_correct=0\n",
    "    # for key, value in tqdm(train_dict.items()):\n",
    "    for key, value in train_dict.items():\n",
    "        if Model.tag_dict.get(key):\n",
    "            total+=len(value)\n",
    "            current_correct=0\n",
    "            pred_tags_list=Model.predict(value)\n",
    "            for pred_tags in pred_tags_list:\n",
    "                if key in pred_tags:\n",
    "                    total_correct+=1\n",
    "                    current_correct+=1\n",
    "            if epoch:\n",
    "                acc=current_correct/len(value)\n",
    "                acc_dict[key+\"_train\"].append([epoch, acc])\n",
    "    if not epoch:\n",
    "        print(total_correct/total)\n",
    "\n",
    "def predict_testset(epoch=None):\n",
    "    total=0\n",
    "    total_correct=0\n",
    "    # for key, value in tqdm(train_dict.items()):\n",
    "    for key, value in test_dict.items():\n",
    "        if Model.tag_dict.get(key):\n",
    "            total+=len(value)\n",
    "            current_correct=0\n",
    "            pred_tags_list=Model.predict(value)\n",
    "            for pred_tags in pred_tags_list:\n",
    "                if key in pred_tags:\n",
    "                    total_correct+=1\n",
    "                    current_correct+=1\n",
    "            if epoch:\n",
    "                acc=current_correct/len(value)\n",
    "                acc_dict[key+\"_test\"].append([epoch, acc])\n",
    "    if not epoch:\n",
    "        print(total_correct/total)\n",
    "\n",
    "def predict_train_and_paint():\n",
    "    predict_result={}\n",
    "    for key, value in tqdm(train_dict.items()):\n",
    "        pred_tags_list=Model.predict(value)\n",
    "        for pred_tags, sample in zip(pred_tags_list, value):\n",
    "            pred_tag=pred_tags[0]\n",
    "            if not predict_result.get(pred_tag):\n",
    "                predict_result[pred_tag]=[sample]\n",
    "            else:\n",
    "                predict_result[pred_tag].append(sample)\n",
    "    predict_result=dict(sorted(predict_result.items(), key=lambda x:x[0]))\n",
    "    if INPUT_DIM==2:\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            plt.scatter(t[:, 0], t[:, 1], label=tag)\n",
    "        # plt.legend()\n",
    "        plt.title(\"TRAIN\")\n",
    "    elif INPUT_DIM==3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            ax.scatter(t[:, 0].cpu(), t[:, 1].cpu(), t[:, 2].cpu(), label=tag)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        # ax.legend()\n",
    "        plt.title(\"TRAIN\")\n",
    "\n",
    "def predict_test_and_paint():\n",
    "    predict_result={}\n",
    "    for key, value in tqdm(test_dict.items()):\n",
    "        pred_tags_list=Model.predict(value)\n",
    "        for pred_tags, sample in zip(pred_tags_list, value):\n",
    "            pred_tag=pred_tags[0]\n",
    "            if not predict_result.get(pred_tag):\n",
    "                predict_result[pred_tag]=[sample]\n",
    "            else:\n",
    "                predict_result[pred_tag].append(sample)\n",
    "    predict_result=dict(sorted(predict_result.items(), key=lambda x:x[0]))\n",
    "    if INPUT_DIM==2:\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            plt.scatter(t[:, 0], t[:, 1], label=tag)\n",
    "        # plt.legend()\n",
    "        plt.title(\"TEST\")\n",
    "    elif INPUT_DIM==3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        for tag in predict_result:\n",
    "            t=torch.tensor([i.tolist() for i in predict_result[tag]])\n",
    "            ax.scatter(t[:, 0].cpu(), t[:, 1].cpu(), t[:, 2].cpu(), label=tag)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        # ax.legend()\n",
    "        plt.title(\"TEST\")\n",
    "\n",
    "def plot_acc():\n",
    "    plt.figure()\n",
    "    for key in [i for i in acc_dict.keys() if \"train\" in i]:\n",
    "        t=torch.tensor(acc_dict[key])\n",
    "        plt.plot(t[:,0], t[:,1])\n",
    "    plt.ylim(top=1.1, bottom=0)\n",
    "    plt.legend([i for i in acc_dict.keys() if \"train\" in i])\n",
    "    plt.title(\"Train ACC\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    for key in [i for i in acc_dict.keys() if \"test\" in i]:\n",
    "        t=torch.tensor(acc_dict[key])\n",
    "        plt.plot(t[:,0], t[:,1])\n",
    "    plt.ylim(top=1.1, bottom=0)\n",
    "    plt.legend([i for i in acc_dict.keys() if \"test\" in i])\n",
    "    plt.title(\"Test ACC\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_DIM=100\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = torch.nn.Linear(INPUT_DIM, INNER_DIM)\n",
    "        init_network(self)\n",
    "\n",
    "    def forward(self, feature_vecs):\n",
    "        out = self.fc(feature_vecs)\n",
    "        return out\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = torch.nn.Linear(INNER_DIM, INPUT_DIM)\n",
    "        init_network(self)\n",
    "\n",
    "    def forward(self, tag_vecs):\n",
    "        out = self.fc(tag_vecs)\n",
    "        return out\n",
    "\n",
    "class EmptyLM(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t=t.reshape(1,-1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(888)\n",
    "Model=ContinualLearningModel(\n",
    "    EmptyLM,\n",
    "    Classifier,\n",
    "    Generator,\n",
    "    0.001,\n",
    "    0.001\n",
    ")\n",
    "\n",
    "epoch=0\n",
    "acc_dict={}\n",
    "for tag in train_dict:\n",
    "    if acc_dict.get(tag)==None:\n",
    "        acc_dict[tag+\"_test\"]=[]\n",
    "        acc_dict[tag+\"_train\"]=[]\n",
    "batch_train(8)\n",
    "plt.figure()\n",
    "plt.plot(Model.loss_dict[\"Classifier Batch Train Loss\"], label=\"Batch Train Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predict_trainset()\n",
    "predict_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(888)\n",
    "Model=ContinualLearningModel(\n",
    "    EmptyLM,\n",
    "    Classifier,\n",
    "    Generator,\n",
    "    0.001,\n",
    "    0.005\n",
    ")\n",
    "\n",
    "epoch=0\n",
    "acc_dict={}\n",
    "for tag in train_dict:\n",
    "    if acc_dict.get(tag)==None:\n",
    "        acc_dict[tag+\"_test\"]=[]\n",
    "        acc_dict[tag+\"_train\"]=[]\n",
    "continual_train_without_generator()\n",
    "plt.figure()\n",
    "plt.plot(Model.loss_dict[\"Classifier Continual Baseline Train Loss\"], label=\"Baseline Train Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plot_acc()\n",
    "print()\n",
    "predict_trainset()\n",
    "predict_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(888)\n",
    "Model=ContinualLearningModel(\n",
    "    EmptyLM,\n",
    "    Classifier,\n",
    "    Generator,\n",
    "    0.001,\n",
    "    0.001\n",
    ")\n",
    "\n",
    "epoch=0\n",
    "acc_dict={}\n",
    "for tag in train_dict:\n",
    "    if acc_dict.get(tag)==None:\n",
    "        acc_dict[tag+\"_test\"]=[]\n",
    "        acc_dict[tag+\"_train\"]=[]\n",
    "continual_train()\n",
    "# continual_train()\n",
    "plt.figure()\n",
    "plt.plot(Model.loss_dict[\"Classifier Continual Attach Train Loss\"], label=\"Attach Train Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Model.loss_dict[\"Generator Continual Single Train Loss\"], label=\"Generator\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plot_acc()\n",
    "print()\n",
    "predict_trainset()\n",
    "predict_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train_and_paint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_and_paint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
